{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy import exp,sqrt,log,log10,sign,power,cosh,sinh,tanh,floor\n",
    "rng = np.random.default_rng(12345)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import NullFormatter, MaxNLocator\n",
    "mpl.rcParams.update({\"font.size\": 12})\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_original, Y_original = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#    CHOICE OF PARAMETERS      #\n",
    "################################\n",
    "# number of MNIST digits to keep (e.g., Ndigit=3 keeps 0,1,2)\n",
    "Ndigit=3\n",
    "# number of hidden units\n",
    "L = 3 \n",
    "# use (+1,-1) if SPINS, otherwise use bits (1,0), ising spins\n",
    "SPINS=False  \n",
    "# use one-hot encoding in hidden space if POTTS (use only if SPINS=False)\n",
    "POTTS=False\n",
    "\n",
    "dname='DATA/'\n",
    "################################\n",
    "\n",
    "# x_min =0 if bits, x_min=-1 if SPINS\n",
    "if SPINS:\n",
    "    x_min=-1\n",
    "    level_gap=2.\n",
    "else:\n",
    "    x_min=0\n",
    "    level_gap=1.\n",
    "\n",
    "if POTTS:\n",
    "    str_simul=\"RBM_Potts\"\n",
    "    # in one-hot encoding, number of possible hidden states matches L\n",
    "    Nz=L\n",
    "else:\n",
    "    str_simul=\"RBM\"\n",
    "    # number of possible hidden states: 2**L\n",
    "    Nz=2**L\n",
    "    \n",
    "if POTTS and SPINS: \n",
    "    print(\"\\n\\n>>>>>>>> WARNING:  POTTS and SPINS cannot coexist\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data, and digitalize them two levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen digits:  ('7', '8', '9')\n",
      "Dataset with 21076 points, each with 784 bits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def show_MNIST(x, y=[], z=[], Nex=5, S=1.4, side=0, colors=[], save=False):\n",
    "    \"\"\"Show digits\"\"\"\n",
    "    if side==0: side = int(sqrt(x.shape[1]))\n",
    "    if len(y)<1: y=np.full(Nex,\"\")\n",
    "    colors=np.array(colors)\n",
    "    fig, AX = plt.subplots(1,Nex,figsize=(S*Nex,S))\n",
    "    \n",
    "    for i, img in enumerate(x[:Nex].reshape(Nex, side, side)):\n",
    "        if len(colors)==0: newcmp = \"grey\"\n",
    "        else:\n",
    "            col= colors[0] + (colors[1]-colors[0])*(i+1)/(Nex+1)\n",
    "            newcmp = ListedColormap((col,(1,1,1,1)))\n",
    "        ax=AX[i]\n",
    "        ax.imshow(img, cmap=newcmp)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if len(y)>0: ax.set_title(y[i])\n",
    "        if len(z)>0: ax.set_title(''.join(map(str, z[i])),fontsize=9)\n",
    "    if save: plt.savefig(f\"./FIG/FRAME/RBM_{epoch}_w-a.png\")\n",
    "    plt.show()\n",
    "\n",
    "def MNIST_bit(X,side=28,level=0.5):\n",
    "    NX=len(X)\n",
    "    print(f\"Dataset with {NX} points, each with {len(X[0])} bits\\n\")\n",
    "    if side==14:\n",
    "        X = np.reshape(X,(NX,28,28))\n",
    "        # new value = average over 4 values in a 2x2 square\n",
    "        Xr = 0.25*(X[:,0::2,0::2]+X[:,1::2,0::2]+X[:,0::2,1::2]+X[:,1::2,1::2])\n",
    "        X  = Xr.reshape(NX,side**2)\n",
    "\n",
    "    # binarize data and then convert it to 1/0 or 1/-1\n",
    "    X = np.where(X/255 > level, 1, x_min)\n",
    "    return X.astype(\"int\")\n",
    "\n",
    "\n",
    "# Selecting digits to use\n",
    "list_10_digits = ('0','1','2','3','4','5','6','7','8','9')\n",
    "list_digits = list_10_digits[-Ndigit:] \n",
    "print('Chosen digits: ',list_digits)\n",
    "\n",
    "# keep only X and Y in list_digitssssssssss\n",
    "keep=np.isin(Y_original, list_digits)\n",
    "X_keep,Y=X_original[keep],Y_original[keep]\n",
    "\n",
    "\n",
    "data,label = MNIST_bit(X_keep),Y\n",
    "data,label = data.astype(\"int\"),label.astype(\"int\")\n",
    "\n",
    "# number of data points\n",
    "Nd = len(data)\n",
    "# number of visible units - I.e. total pixels of the image\n",
    "D  = len(data[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract of MNIST-3 data points, binarized\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x140 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x140 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x140 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x140 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Extract of MNIST-{Ndigit} data points, binarized\")\n",
    "for i in range(4): show_MNIST(data[i*20:],Nex=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive divergence (CD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eq(213) page 97, activation via sigmoid\n",
    "# taking into account energy gap 2 for \"spin\" variables (-1,1)\n",
    "#@jit(parallel=True)\n",
    "def CD_step(v_in,wei,bias,details=False,POTTS=False):\n",
    "    \"\"\"\n",
    "        Generates the state on the other layer: \n",
    "        Field \"H\" ->  activation \"a\" -> probability \"p\" -> Spins/bits v_out\n",
    "\n",
    "        Either (v_in=x, wei=w) or (v_in=z, wei=w.T)\n",
    "\n",
    "        details = True --> returns also probability (p) and activation (a) \n",
    "\n",
    "        POTTS means one-hot encoding (used only in hidden space)\n",
    "    \"\"\"\n",
    "    # local \"field\"\n",
    "    H = np.clip(np.dot(v_in.astype(np.float64), wei) + bias, a_min=-300, a_max=300)\n",
    "    # \"activation\" note, it is a sigmoid\n",
    "    a = np.exp(level_gap*H)\n",
    "    n = np.shape(H)\n",
    "    v_out = np.full(n, x_min, dtype=int) # initially, just a list on -1's or 0's\n",
    "    if POTTS: # RBM with a single hidden unit = 1 (that is, \"one-hot encoding\" with L states)\n",
    "        # p: state probability, normalized to 1 over all units=states\n",
    "        \n",
    "        # Probability of turning on a hidden unit\n",
    "        p = a/np.sum(a)\n",
    "        # F: cumulative probability\n",
    "        F = np.cumsum(p)\n",
    "        # pick a state \"i\" randomly with probability p[i]\n",
    "        r = np.random.rand()\n",
    "        i = 0\n",
    "        while r>F[i]:\n",
    "            i+=1\n",
    "        v_out[i] = 1 # activate a single hidden unit\n",
    "    else: # normal Ising RBM\n",
    "        # p: local probability, normalized to 1 for each hidden unit\n",
    "        p = a / (a + 1.)\n",
    "        # at each position i, activate the 1's with local probability p[i]\n",
    "        v_out[np.random.random_sample(n) < p] = 1 \n",
    "\n",
    "    if details: return (v_out,p,a)\n",
    "    else: return v_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_weights_bias(wE, bE, epoch, L, \n",
    "                      side=0,cols=0,thr=0,s=1.5, \n",
    "                      title=False, save=True,cmap=\"bwr\"):\n",
    "    '''\n",
    "    Plot the weights of the RBM, one plot for each hidden unit.\n",
    "    '''\n",
    "    rows = int(np.ceil(L / cols))\n",
    "    if rows==1: rows=2\n",
    "    w=wE[epoch]\n",
    "    b=bE[epoch]\n",
    "    if side==0: side=int(sqrt(len(w)))\n",
    "    if thr==0: thr=4\n",
    "    plt.clf()\n",
    "    fig, AX = plt.subplots(rows, cols+1, figsize=(s*(1+cols),s*rows))\n",
    "    if title: fig.suptitle(f\"epoch = {epoch}\")\n",
    "    k=1\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if rows==1: ax=AX[j+1]\n",
    "            else: ax=AX[i,j+1]\n",
    "            if k<=L:\n",
    "                ax.imshow(w[:,k-1].reshape(side, side), cmap=cmap,vmin=-thr,vmax=thr)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_title(f\"hidden {k}\")\n",
    "            else: fig.delaxes(ax)\n",
    "            k+=1\n",
    "        if i>0:  fig.delaxes(AX[i,0])\n",
    "    \n",
    "    ax=AX[0,0];\n",
    "    im=ax.imshow(b.reshape(side, side), cmap=cmap,vmin=-thr,vmax=thr)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"bias\")\n",
    "    # colobar\n",
    "    cbar_ax = fig.add_axes([0.14, 0.15, 0.024, 0.33])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    S=0.3\n",
    "    plt.subplots_adjust(hspace=S)\n",
    "\n",
    "    if save: plt.savefig(f\"./FIG/FRAME/RBM_{epoch}_w-a.png\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Weights initialization \n",
    "The initialization proposed by Hinton for the bias $a_i$ of a visible unit $v_i$ is given by the formula $ a_i = \\log(\\frac{p_i}{1-p_i})$ (Hinton 2012), where $p_i$ is the fraction of training samples in which the unit $i$ is on. \n",
    "When updating the visible states, $p_i$ corresponds to the probability of having a visible state equal to 1, which is used to stochastically pick the value of each visible unit. The probability of activation for a visible neuron is $P(x_i=1|h)= \\sigma(a_i + \\sum_j h_j w_{ij})$ (Hinton 2012) where $\\sigma(x) = \\frac{1}{1+e^{-x}}$ is a sigmoid function. If we set $w_{ij}\\sim 0$, we have $P(x_i=1) \\sim \\sigma(a_i)$, hence $\\sigma(a_i) = p_i$.\n",
    "\n",
    "The biases are set so that the neurons have on average an activation that matches the distribution of the training data (Mehta 2019). This helps stabilize learning and prevents the model from learning too slowly.\n",
    "In a qualitative way, if a pixel is often active in the dataset ($p\\sim 1$), the bias will be higly positive, encouraging the neuron to be active. On the contrary, if a pixel is rarely active ($p_i \\sim 0$), the bias will be highly negative, discouraging activation. If $p_i = 0.5$, the bias will be zero, meaning the neuron has a neutral activation probability.\n",
    "\n",
    "In the function $Hinton$ _ $bias$ _ $init(x)$ , an average on the data is made for each column obtaining the vector xmean.\n",
    "The vector is then 'refined' setting values that are too close to the lower ($-1$ or $0$) and upper (1) state to a higher (first case) or lower value (second case). This is to avoid divergences when computing the logarithms. \n",
    "Finally, the function returns the vector of biases based on the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial bias of visible units, based on their average value in the dataset\n",
    "# Hinton, \"A Practical Guide to Training Restricted Boltzmann Machines\"\n",
    "def Hinton_bias_init(x):\n",
    "    '''\n",
    "    x ::shape of 'x'(data): (21770,784)\n",
    "    xmean :: does the mean on 'data' for each column -> shape of xmean :(,784)\n",
    "     xmin =0, xmax=1 if SPINS=FALSE, otherwise {-1,+1}\n",
    "    since np.precision is set at 4 -> S = 1e-4\n",
    "    level_gap :: is the difference in values between the max (1) and the min (x_min)\n",
    "    np.clip :: avoid minimum maximum overflow, inf and -inf values.\n",
    "    '''\n",
    "    xmean=np.array(np.mean(x,axis=0))\n",
    "    # remove values at extrema, to avoid divergences in the log's\n",
    "    S = 1e-4\n",
    "    x1,x2 = x_min+S,1-S \n",
    "    xmean[xmean<x1] = x1\n",
    "    xmean[xmean>x2] = x2\n",
    "    return (1/level_gap)*np.clip(log(xmean-x_min) - log(1-xmean),-300,300)\n",
    "    \n",
    "# range of each initial weight\n",
    "# Glorot and Bengio, \"Understanding the difficulty of training deep feedforward neural networks\"\n",
    "sigma = sqrt(4. / float(L + D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We trained the RBM on digits 7,8,9, trying with number of hidden units L $\\in [3,4,5,6,7]$, and for each value we tried different CD steps, $Nt \\in [2,4,6,8,10,12]$.\n",
    "\n",
    "Log-likelihood generally increases during training, what you can see in the resume above are graphs of the LL taken every 5 epochs to spare us computational time and get as soon as possible an overview.\n",
    "\n",
    "What we see is that number of CD steps matters a little bit in LL increase, 2-3 points, and it depends more on the number of hidden units. Best final values are for L=7. It is interesting to see that sometimes LL stalls after a initial steep increase. This could mean that the model fits the data soon, and then keeps wandering in the hyperspace. \n",
    "\n",
    "As Hinton suggests, best results with multidimensional data are reached with more hidden units than the necessary bits to describe the label, but would be optimal to have the same number of hidden units as the length of the data vector. With our computational capabilities this is very difficult to realize, it would mean 20-30 hidden units.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "def generate_configurations(L):\n",
    "    \"\"\"Generate all binary configurations of length L.\"\"\"\n",
    "    return np.array(list(it.product((0,1), repeat=L)), dtype=np.int64)\n",
    "\n",
    "def compute_log_likelihood(partition,data, a, b, w):\n",
    "    log_likelihoods = np.zeros(len(data))  # Preallocate array\n",
    "    all_conf = generate_configurations(L)  # Compute binary configs once\n",
    "\n",
    "    Hz_cache = np.array([H(z) for z in all_conf])  # Precompute H(z)\n",
    "\n",
    "    for i, x in enumerate(data): \n",
    "        Z_x = 0.0\n",
    "        for Hz, z in zip(Hz_cache, all_conf):\n",
    "            E_xz = -np.dot(Hz, x) - np.dot(b, z)\n",
    "            Z_x += np.exp(-E_xz)\n",
    "\n",
    "        log_likelihoods[i] = np.clip(np.log(Z_x) - partition, a_min=-700, a_max=+7000)\n",
    "\n",
    "    return np.mean(log_likelihoods)\n",
    "\n",
    "def H(z):  \n",
    "    return a + np.dot(w, z)  \n",
    "\n",
    "def G(z):  \n",
    "    return np.prod(np.exp(b * z))\n",
    "\n",
    "def partition_function(configurations):\n",
    "    sum_values = 0.0  # Use scalar accumulation\n",
    "\n",
    "    for z in configurations:\n",
    "        Hz = H(z)\n",
    "        produttoria_H = np.prod(1 + np.exp(Hz))\n",
    "        sum_values += G(z) * produttoria_H\n",
    "\n",
    "    return np.log(sum_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'img/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# regex\u001b[39;00m\n\u001b[1;32m      9\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLH_epoch150_L(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md)_CD(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)_lr0.05.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m files \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     (f, \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, f))\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (match \u001b[38;5;241m:=\u001b[39m pattern\u001b[38;5;241m.\u001b[39mmatch(f)) \n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Sort by L first, then CD\u001b[39;00m\n\u001b[1;32m     18\u001b[0m files\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: (x[\u001b[38;5;241m1\u001b[39m], x[\u001b[38;5;241m2\u001b[39m]))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'img/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "folder_path = \"img/\"\n",
    "# regex\n",
    "pattern = re.compile(r\"LLH_epoch150_L(\\d)_CD(\\d+)_lr0.05.png\")\n",
    "\n",
    "files = [\n",
    "    (f, int(match.group(1)), int(match.group(2)), os.path.join(folder_path, f))\n",
    "    for f in os.listdir(folder_path)\n",
    "    if (match := pattern.match(f)) \n",
    "]\n",
    "\n",
    "# Sort by L first, then CD\n",
    "files.sort(key=lambda x: (x[1], x[2]))\n",
    "# Extract only filenames\n",
    "sorted_filenames = [f[0] for f in files]\n",
    "\n",
    "row,cols = 5,6\n",
    "fig,axes = plt.subplots(row,cols, figsize=(15,10), layout='constrained')\n",
    "axes = axes.flatten()\n",
    "for i, img in enumerate(sorted_filenames[:row*cols]):\n",
    "    image = Image.open('img/' +img)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up RBM for cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same code used for training to perform a cross validation. This time we only select the 6 best models from the previous discussion.\n",
    "In the code below are shown the hyperparameters of the last best model (number 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L, hidden units: 5\n",
      "SPINS: False\n",
      "POTTS: False\n",
      "gamma: 0.001\n",
      "GRAD: SGD\n",
      "Nt: 2\n",
      "Epochs: 190\n",
      "Nmini: 45\n",
      "Nini: 10\n",
      "Nfin: 450\n",
      "D=784\tsample size\n",
      "L=5\tnr. z states\n",
      "Gradient descent type: SGD\n",
      "learning rate        = 1.0 --> 0.25\n",
      "gamma=0.001\tregularization\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "## Hyper parameters::\n",
    "L = 5\n",
    "print(f'L, hidden units: {L}')\n",
    "SPINS = False\n",
    "print(f'SPINS: {SPINS}')\n",
    "POTTS = False\n",
    "print(f'POTTS: {POTTS}')\n",
    "gamma = .001\n",
    "print(f'gamma: {gamma}')\n",
    "GRAD = 'SGD'\n",
    "print(f'GRAD: {GRAD}')\n",
    "Nt = 2\n",
    "print(f'Nt: {Nt}')\n",
    "Nepoch = 190\n",
    "print(f'Epochs: {Nepoch}')\n",
    "Nmini = 45\n",
    "print(f'Nmini: {Nmini}')\n",
    "N_ini = 10\n",
    "print(f'Nini: {N_ini}')\n",
    "N_fin = 450\n",
    "print(f'Nfin: {N_fin}')\n",
    "\n",
    "\n",
    "## setup for gradient choice & gamma\n",
    "if GRAD==\"SGD\":\n",
    "    l_rate_ini,l_rate_fin=1.0,0.25\n",
    "if GRAD==\"RMSprop\":\n",
    "    beta,epsilon=0.9,1e-4\n",
    "    l_rate_ini,l_rate_fin=0.05,0.05\n",
    "    print(\"epsilon=\",epsilon)\n",
    "\n",
    "print(f\"D={D}\\tsample size\\nL={L}\\tnr. z states\")\n",
    "print(\"Gradient descent type:\",GRAD)\n",
    "print(f\"learning rate        = {l_rate_ini} --> {l_rate_fin}\")\n",
    "if gamma!=0: print(f\"gamma={gamma}\\tregularization\")\n",
    "\n",
    "##setup for spin/potts/other thing\n",
    "if SPINS:\n",
    "    x_min=-1\n",
    "    level_gap=2.\n",
    "else:\n",
    "    x_min=0\n",
    "    level_gap=1.\n",
    "\n",
    "if POTTS:\n",
    "    str_simul=\"RBM_Potts\"\n",
    "    Nz=L\n",
    "else:\n",
    "    str_simul=\"RBM\"\n",
    "    Nz=2**L\n",
    "    \n",
    "if POTTS and SPINS: \n",
    "    print(\"\\n\\n>>>>>>>> WARNING:  POTTS and SPINS cannot coexist\\n\\n\")\n",
    "\n",
    "stringa = f'#L SPIN POTTS gamma Nt Nepoch Nmini Nini Nfin Grad'\n",
    "stringa2 = [L, SPINS, POTTS, gamma, Nt, Nepoch, Nmini, N_ini, N_fin, GRAD]\n",
    "with open(f'llh{int((code := time.time()))}.txt', 'a') as add:\n",
    "    print(stringa, file=add)\n",
    "    print(stringa2, file=add)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Run\n",
    "\n",
    "We perform the cross validation by running the learning algorithm using different random seeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nepoch=190\n",
      "Nmini=45\n",
      "Starting the training\n",
      "END of learning phase\n"
     ]
    }
   ],
   "source": [
    "for seed in [1, 12, 123, 1234, 12345, 123457]:\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # initial weights from a Normal distr. (see literature, e.g. page 98 of Mehta's review)\n",
    "    w = sigma * np.random.randn(D,L)\n",
    "    # using Hinton initialization of visible biases\n",
    "    a = Hinton_bias_init(data)\n",
    "    # hidden biases initialized to zero\n",
    "    b = np.zeros(L)\n",
    "    print(f\"Nepoch={Nepoch}\\nNmini={Nmini}\")\n",
    "    # recording history of weights (\"E\" means epoch)\n",
    "    wE,aE,bE=np.zeros((Nepoch+1,D,L)),np.zeros((Nepoch+1,D)),np.zeros((Nepoch+1,L)) \n",
    "    wE[0],aE[0],bE[0]=np.copy(w),np.copy(a),np.copy(b)\n",
    "    gwE,gw2E,gwE_d,gwE_m = np.zeros_like(wE),np.zeros_like(wE),np.zeros_like(wE),np.zeros_like(wE)\n",
    "    gaE,ga2E,gaE_d,gaE_m = np.zeros_like(aE),np.zeros_like(aE),np.zeros_like(aE),np.zeros_like(aE)\n",
    "    gbE,gb2E,gbE_d,gbE_m = np.zeros_like(bE),np.zeros_like(bE),np.zeros_like(bE),np.zeros_like(bE)\n",
    "    miniE = np.zeros(Nepoch+1)\n",
    "    pzE=np.zeros((Nepoch+1,Nz))\n",
    "    \n",
    "    if GRAD==\"RMSprop\": \n",
    "        gw2,ga2,gb2 = np.zeros_like(w),np.zeros_like(a),np.zeros_like(b)\n",
    "    \n",
    "    indices=np.arange(Nd).astype(\"int\")\n",
    "    #plot_weights_bias(wE, aE, 0, L, cols=L//2, save=False)\n",
    "    \n",
    "    # for the plot with panels\n",
    "    Ncols=min(8,max(2,L//2))\n",
    "    \n",
    "    if POTTS: print(\"Starting the training, POTTS=True\")\n",
    "    else: print(\"Starting the training\")\n",
    "    #for L in np.arange(4,9,1):\n",
    "    \n",
    "    configurations = generate_configurations(L)\n",
    "    log_likelihoods = []\n",
    "    lista_epoch_grafico = []\n",
    "    # Note: here an epoch does not analyze the whole dataset\n",
    "    for epoch in range(1,1+Nepoch):\n",
    "        # q maps epochs to interval [0,1]\n",
    "        q = (epoch-1.)/(Nepoch-1.) \n",
    "        # N, size of the mini batch\n",
    "        # stays closer to N_ini for some time, then it progressively accelerates toward N_fin\n",
    "        N = int(N_ini + (N_fin-N_ini)*(q**2))\n",
    "        #  l_rate interpolates between initial and final value\n",
    "        l_rate = l_rate_ini + (l_rate_fin-l_rate_ini)*q\n",
    "    \n",
    "        for mini in range(Nmini):\n",
    "            # initializitation for averages in minibatch\n",
    "            # visible variables \"v\" --> \"x\"\n",
    "            #  hidden variables \"h\" --> \"z\"\n",
    "            x_data, x_model = np.zeros(D),np.zeros(D)\n",
    "            z_data, z_model = np.zeros(L),np.zeros(L)\n",
    "            xz_data,xz_model= np.zeros((D,L)),np.zeros((D,L))\n",
    "            pz = np.zeros(L)\n",
    "    \n",
    "            # Minibatch of size N: points randomply picked (without repetition) from data\n",
    "            selected = np.random.choice(indices,N,replace=False)\n",
    "           # if epoch==1 and mini<=3: print(selected)\n",
    "    \n",
    "            for k in range(N):\n",
    "                ###################################\n",
    "                x0 = data[selected[k]]\n",
    "                # positive CD phase: generating z from x[k]\n",
    "                z = CD_step(x0,w,b,POTTS=POTTS)\n",
    "                x_data  += x0\n",
    "                z_data  += z\n",
    "                xz_data += np.outer(x0,z)\n",
    "                # fantasy\n",
    "                zf=np.copy(z)\n",
    "                # Contrastive divergence with Nt steps\n",
    "                for t in range(Nt):\n",
    "                    # negative CD pzase: generating fantasy xf from fantasy zf\n",
    "                    xf = CD_step(zf,w.T,a)\n",
    "                    # positive CD phase: generating fantasy zf from fantasy xf \n",
    "                    zf = CD_step(xf,w,b,POTTS=POTTS)\n",
    "                x_model += xf\n",
    "                z_model += zf\n",
    "                xz_model+= np.outer(xf,zf)\n",
    "                # recording probability of encoding in z-space, if POTTS\n",
    "                if POTTS: pz[zf]+=1\n",
    "                ###################################\n",
    "    \n",
    "            # gradient of the likelihood: follow it along its positive direction\n",
    "            gw_d,gw_m = xz_data/N, xz_model/N\n",
    "            ga_d,ga_m = x_data/N, x_model/N\n",
    "            gb_d,gb_m = z_data/N, z_model/N\n",
    "            gw=np.copy(gw_d - gw_m)\n",
    "            ga=np.copy(ga_d - ga_m)\n",
    "            gb=np.copy(gb_d - gb_m)\n",
    "    \n",
    "            # gradient ascent step\n",
    "            if GRAD==\"RMSprop\":\n",
    "                # RMSprop gradient ascent\n",
    "                gw2 = beta*gw2+(1-beta)*np.square(gw)\n",
    "                ga2 = beta*ga2+(1-beta)*np.square(ga)\n",
    "                gb2 = beta*gb2+(1-beta)*np.square(gb)\n",
    "                w += l_rate*gw/sqrt(epsilon+gw2)\n",
    "                a += l_rate*ga/sqrt(epsilon+ga2)\n",
    "                b += l_rate*gb/sqrt(epsilon+gb2)\n",
    "            else: \n",
    "                # defaulting to the vanilla stochastic gradient ascent (SGD)\n",
    "                w += l_rate*gw\n",
    "                a += l_rate*ga\n",
    "                b += l_rate*gb\n",
    "            # regularization (LASSO)\n",
    "            if gamma>0.:\n",
    "                w -= (gamma*l_rate)*sign(w)\n",
    "                a -= (gamma*l_rate)*sign(a)\n",
    "                b -= (gamma*l_rate)*sign(b)\n",
    "    \n",
    "        wE[epoch],gwE[epoch],gwE_d[epoch],gwE_m[epoch]=np.copy(w),np.copy(gw),np.copy(gw_d),np.copy(gw_m)\n",
    "        aE[epoch],gaE[epoch],gaE_d[epoch],gaE_m[epoch]=np.copy(a),np.copy(ga),np.copy(ga_d),np.copy(ga_m)\n",
    "        bE[epoch],gbE[epoch],gbE_d[epoch],gbE_m[epoch]=np.copy(b),np.copy(gb),np.copy(gb_d),np.copy(gb_m)\n",
    "        miniE[epoch]=N\n",
    "        if POTTS: pzE[epoch] = pz/np.sum(pz)\n",
    "        #print(\"epoch\",epoch,\"/\",Nepoch,\" Nt:\",Nt,\" N:\",N,\" L:\",L,\n",
    "             # \" rate:\",l_rate,\" gam:\",gamma,\"SPINS=\",SPINS,\"POTTS=\",POTTS)\n",
    "    \n",
    "        #if Nepoch<=100 or epoch%20==0 or epoch==Nepoch:\n",
    "            #plot_weights_bias(wE, aE, epoch, L, cols=Ncols, save=False)\n",
    "    \n",
    "        if epoch==(Nepoch):\n",
    "            partition = partition_function(configurations)\n",
    "            log_likelihood = compute_log_likelihood(partition,data, a=a, b=b, w=w,)\n",
    "            #with open(f'llh{int(code)}.txt', 'a') as add:\n",
    "                #print(log_likelihood, file=add)\n",
    "        str_time_completion = datetime.datetime.now().strftime(\"_%Y%m%d_%H%M\")\n",
    "    print(\"END of learning phase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model scores\n",
    "We plot the scores related to the 6 best models that we chose. We see that we get for all models approximately the same error bars and the same result.\n",
    "We also note that five out of six models have as hyperparameter for the optimizer the value 'RMSprop', which indicates that maybe this value could be better than 'SGD'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llh1742571832.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7149/1242055569.py:6: UserWarning: loadtxt: input contained no data: \"llh1742571832.txt\"\n",
      "  llh_list.append(np.loadtxt(file.name, skiprows=2))\n"
     ]
    }
   ],
   "source": [
    "llh_list = []\n",
    "file_names = []\n",
    "with os.scandir() as files:\n",
    "    for file in files:\n",
    "        if file.name.startswith('llh') and file.name.endswith('.txt'):\n",
    "            llh_list.append(np.loadtxt(file.name, skiprows=2))\n",
    "            file_names.append(file.name)\n",
    "print(file_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model|L|SPIN|POTTS|gamma|Nt|Nepoch|Nmini|Nini|Nfin|Grad|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|0|7|False|False|0.001|4|300|30|5|100|RMSprop|\n",
    "|1|10| False| False|0.001| 1| 200| 10| 5|325| RMSprop|\n",
    "|2|5|False|False|0.001|2|190|45|10|450|SGD|\n",
    "|3|10|False|True|0.01|1|200|10|5|10|RMSprop|\n",
    "|4|10| False| False|0.01| 1| 200| 10| 5| 10| RMSprop|\n",
    "|5|10|False|False|0.001|7|350|10|5|325|RMSprop|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'x' and 'y' must have the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstrained\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorbar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mllh_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllh_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myerr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllh_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/src/ambiente/lib/python3.12/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/src/ambiente/lib/python3.12/site-packages/matplotlib/axes/_axes.py:3633\u001b[0m, in \u001b[0;36mAxes.errorbar\u001b[0;34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[0m\n\u001b[1;32m   3631\u001b[0m x, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(x, y)  \u001b[38;5;66;03m# Make sure all the args are iterable.\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y):\n\u001b[0;32m-> 3633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must have the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3635\u001b[0m everymask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_errorevery_to_mask(x, errorevery)\n\u001b[1;32m   3637\u001b[0m label \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'x' and 'y' must have the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.errorbar(range(len(llh_list)), np.mean(llh_list, axis=0), yerr=np.std(llh_list, axis=0), fmt='ok', lw=1, capsize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test generative power of the trained RBM\n",
    "\n",
    "DA RUNNARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m t1\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# positive CD phase: generating fantasy zf from fantasy xf\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m zf \u001b[38;5;241m=\u001b[39m CD_step(xf,\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39mwE[ee],\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39mbE[ee],POTTS\u001b[38;5;241m=\u001b[39mPOTTS)\n\u001b[1;32m     16\u001b[0m traj_z[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(zf)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# negative CD pzase: generating fantasy xf from fantasy zf\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wE' is not defined"
     ]
    }
   ],
   "source": [
    "ee=-1 ##\n",
    "NN=200\n",
    "traj_x,traj_z = np.zeros((NN+2,D)), np.zeros((NN+2,L))\n",
    "xf=np.copy(data[np.random.randint(Nd)])\n",
    "traj_x[0]=np.copy(xf)\n",
    "\n",
    "# AF: multiply weights and biases by a number >1 to achieve a more deterministic behavior,\n",
    "# equivalent to lower the temperature in a Boltzmann weight -> select lowest energies\n",
    "# Note: here, this is done in the negative CD step only\n",
    "AF=1.\n",
    "\n",
    "for t in range(NN):\n",
    "    t1=t+1\n",
    "    # positive CD phase: generating fantasy zf from fantasy xf\n",
    "    zf = CD_step(xf,1*wE[ee],1*bE[ee],POTTS=POTTS)\n",
    "    traj_z[t] = np.copy(zf)\n",
    "    # negative CD pzase: generating fantasy xf from fantasy zf\n",
    "    xf = CD_step(zf,AF*wE[ee].T,AF*aE[ee])\n",
    "    traj_x[t1] = np.copy(xf)\n",
    "\n",
    "\n",
    "plot_weights_bias(wE, aE, Nepoch, L, cols=Ncols, save=False)\n",
    "\n",
    "col0,col1,col2,col3,col4=(0.8,0,0,1),(1,0.6,0,1),(0,.7,0,1),(0.2,0.2,1,1),(1,0,1,1)\n",
    "show_MNIST(traj_x[0:],Nex=10,colors=(col0,col1))\n",
    "show_MNIST(traj_x[10:],Nex=10,colors=(col1,col2))\n",
    "show_MNIST(traj_x[20:],Nex=10,colors=(col2,col3))\n",
    "show_MNIST(traj_x[40:],Nex=10,colors=(col3,col4))\n",
    "print(\"L:\",L,\"    amplification of weights:\",AF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambiente",
   "language": "python",
   "name": "ambiente"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
