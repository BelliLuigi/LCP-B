








import numpy as np

import os
import json
from keras.optimizers import SGD
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.callbacks import EarlyStopping
import keras_tuner
from kerastuner.engine.trial import Trial
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib.ticker import MultipleLocator
from sklearn.preprocessing import StandardScaler

rng = np.random.default_rng(1758)

plt.rcParams['font.size'] = 13



get_ipython().run_line_magic("run", " useful.py")





TYPE=3
# data point size
L=8
# span of each component
B=10
x = np.loadtxt(filename("data",L,TYPE), delimiter=' ')
y = np.loadtxt(filename("labels",L,TYPE), delimiter=' ')
y = y.astype("int")


def Standardize(x,m,s):
    """
    Rescales each component using its mean and standard deviation
    """
    N = len(x)
    # assuming len(m)=len(s)=len(x[0])
    mm,ss = np.tile(m,(N,1)), np.tile(s,(N,1))
    return (x-mm)/ss

def prepare_data(x,y):
    """
    Does rescaling, and divides the input data into training and test set.
    """
    perc_train=0.8
    
    N=len(x)
    N_train = int(perc_train * N)
    x_mean = np.mean(x,axis=0)
    x_std  = np.std(x,axis=0)
    
    x = Standardize(x,x_mean,x_std)
    
    (x_train, y_train) = (x[0:N_train],y[0:N_train])
    (x_test, y_test) = (x[N_train:],y[N_train:])
    return x_train,y_train,x_test,y_test


x_train,y_train,x_test,y_test=prepare_data(x,y)





#### We edited the class RandomSearch to be able to plot scores of each trials ###############################

class RandomSearch(keras_tuner.RandomSearch):
    histories = {}

    def on_epoch_end(self, trial, model, epoch, logs=None):
        trial_id = trial.trial_id
        trial_history = self.histories.setdefault(trial_id, {})
        for metric, value in logs.items(): trial_history.setdefault(metric, []).append(value)

    def on_trial_end(self, trial):
        super().on_trial_end(trial)

        self.plot_and_save_history(trial)

    def plot_and_save_history(self, trial: Trial):
        trial_id = trial.trial_id
        trial_history = self.histories[trial_id]

        # Create directory for trial if it doesn't exist
        trial_dir = self.get_trial_dir(trial_id)
        os.makedirs(trial_dir, exist_ok=True)

        # Save history to JSON file
        history_file = os.path.join(trial_dir, "history.json")
        with open(history_file, "w") as f:
            json.dump(trial_history, f, indent=4)

    def plot_best_trials(self, num_models=5, wrap_columns=4, figure_size=(20,5), suffix=""):
        best_trials = self.oracle.get_best_trials(num_models)
        num_trials = len(best_trials)

        rows = (num_trials - 1) // wrap_columns + 1
        cols = min(num_trials, wrap_columns)

        fig, axes = plt.subplots(rows, cols, figsize=figure_size, layout='constrained')

        for i, trial in enumerate(best_trials):
            trial_id = trial.trial_id
            trial_dir = self.get_trial_dir(trial_id)
            history_file = os.path.join(trial_dir, "history.json")

            with open(history_file, "r") as f:
                trial_history = json.load(f)

            ax = axes[i // cols, i % cols] if rows > 1 else axes[i]
            for metric_name, metric_values in trial_history.items():
                ax.plot(metric_values, label=f"{metric_name}")

            ax.set_title(f"Trial {trial_id}")
            ax.set_xlabel("Step")
            ax.set_ylabel("Value")
            ax.yaxis.set_major_locator(MultipleLocator(0.1))
            ax.set_xlim(0, 400)
            ax.legend(fontsize=9)
    
#### END of the RandomSearch() class editing ##########################################################





def build_model(hp):
    model = Sequential()
    
    # Input layer
    model.add(Dense(L, input_shape=(L,), activation='relu'))
    hidd_active = hp.Choice('hidd_activation', ['sigmoid','relu','elu'])
    
    # 3 hidden layers
    for layer_num in range(1, 4):
        model.add(Dense(20, activation=hidd_active))
        model.add(Dropout(hp.Float(f'Dropout_{layer_num}', min_value=0, max_value=0.2, step=0.1)))

    # Output layer
    model.add(Dense(1,activation='sigmoid'))
    learning_rate = hp.Choice('lr', [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1])
    hyper_optimizer = hp.Choice('optimizer', ['adam', 'sgd_nesterov', 'RMSprop', 'adamax', 'adagrad'])

    # Define sgd_nesterov
    if hyper_optimizer == 'sgd_nesterov': hyper_optimizer = SGD(learning_rate=learning_rate, nesterov=True)
        
    model.compile(loss='binary_crossentropy', optimizer=hyper_optimizer, metrics=["accuracy"])
    return model





build_model(keras_tuner.HyperParameters()) # Construction of the model

# tuner definition
tuner = RandomSearch(hypermodel=build_model, 
                     objective="val_accuracy", # Tuner objective to maximize/minimize. We choose to maximize the validation
                     ## accuracy so as to pick a lower epoch number in case of overfitting.
                     max_trials=15,  # Number of models to be built.
                     executions_per_trial=1, # originally it was set at 3 trials in case of some errors happening due to
                     ## limited RAM or whatsoever.
                     overwrite=True, # avoids considering old models of previous runs.
                     project_name='search'# directory where trials are saved.
                     )
tuner.search(x_train[200:], y_train[200:], epochs=400, validation_data=(x_train[:200], y_train[:200])) # We use 200 points from the training set as the validation set


# We only display the selected best models' results for readability
tuner.results_summary(num_trials=4)
models = tuner.get_best_models(num_models=4) # We selected models with validation accuracy above 0.95
best_hp = tuner.get_best_hyperparameters(num_trials=4)


print(best_hp[0])


tuner.plot_best_trials(num_models=4, figure_size=(20,6)) # Scores vs epoch of the best 4 models.
plt.show()





def k_fold_cross_validation(x_train, y_train, k, models):
    # Initialize holders
    best = -1 # Best model
    best_perf = -1 # Best score
    results = [] # List to store performance of each model
    histories = []
    # Divide training set in K folds
    idx = rng.permutation(np.arange(x_train.shape[0]))
    x_folds, y_folds = np.array_split(x_train[idx, :], k), np.array_split(y_train[idx], k)
    
    for i in range(len(models)):
        model_perf = []  # Stores each k-th score
        for test in range(k):
            # Define validation and training set
            x_train_fold = np.concatenate([x for i, x in enumerate(x_folds) if i != test])
            y_train_fold = np.concatenate([x for i, x in enumerate(y_folds) if i != test])
            x_validate_fold, y_validate_fold = x_folds[test], y_folds[test]
            k_model = tuner.hypermodel.build(best_hp[i])
            k_model.fit(x_train_fold, y_train_fold, epochs=400, verbose=0, validation_data=(x_validate_fold, y_validate_fold), callbacks=EarlyStopping(patience=5))
            # Accumulates the performance
            model_perf.append(k_model.evaluate(x_validate_fold, y_validate_fold, verbose=0)[1])        
        results.append(((curr_perf := np.mean(model_perf)), np.std(model_perf))) # Average and std over the k-folds
        # if the current model performs better than best, updates best__
        if (best_perf < curr_perf): best, best_perf = models[i], curr_perf
        #Below: return best model, its index, and list of performance results for each model
    return best, results

best_model, results = k_fold_cross_validation(x_train, y_train, 5, models)
print(results) #Performance of each model.


fig, ax = plt.subplots()
fig.suptitle('Validation Accuracies')
ax.errorbar((x_CV := range(len(results))), (y_CV := [results[i][0] for i in x_CV]), yerr=[results[i][1] for i in x_CV], fmt='ok', capsize=2, elinewidth=1)
for i, txt in enumerate([2,3,7,11]): ax.annotate(txt, (x_CV[i] + 0.03, y_CV[i]+0.0005))
ax.get_xaxis().set_ticks([])
ax.set_ylabel('Accuracies')
ax.set_xlabel('Trials')
plt.show()





fit = best_model.fit(x_train, y_train, batch_size = 50, validation_data=(x_test,y_test), verbose=0) # Training best model and evaluating it using the test dataset





def train_data(x_train,y_train,x_test,y_test):
    '''
    Fits train and test set using the best model found above, and plots the relative scores.
    '''
    nepoch = 400
    fit = best_model.fit(x_train, y_train,
               epochs = nepoch, batch_size = 50,
               validation_data=(x_test,y_test),
               verbose=0)
    
    fig,AX=plt.subplots(1,2,figsize=(12,5.), layout='constrained')
    ax=AX[0]
    ax.plot(fit.history['accuracy'],label="train",c="b", lw=0.7)
    ax.plot(fit.history['val_accuracy'],label="test",c="r", lw=0.7)
    ax.set_xlabel('Epoch')
    ax.set_ylabel("Accuracy")
    ax.set_xlim(0,400)
    ax.legend()
    ax=AX[1]
    ax.plot(fit.history['loss'],label="train",c="b", lw=0.7)
    ax.plot(fit.history['val_loss'],label="test",c="r", lw=0.7)
    ax.set_xlabel('Epoch')
    ax.set_xlim(0,400)
    ax.set_ylabel("Loss")
    ax.legend()


 
x_train,y_train,x_test,y_test=prepare_data(x,y)
train_data(x_train,y_train,x_test,y_test)






x_mean = np.mean(x,axis=0)
x_std  = np.std(x,axis=0)
dX = .1
X1 = np.arange(0,10+dX, dX)
LG = len(X1)
X, Y = np.meshgrid(X1, X1)
allXY = np.reshape((np.array((X,Y)).T),(LG**2,2))
grid = np.random.rand(LG**2,L)*B
grid[:,:2] = allXY
grid_r=Standardize(grid,x_mean,x_std)

pred = best_model.predict(grid_r, verbose=0)

fig,AX=plt.subplots(1,3,figsize=(16,5.), layout='constrained')
fig.suptitle('Results', weight='bold',fontsize=20)
ax=AX[0]
ax.scatter(x[:,0],x[:,1],c=y,s=6)
ax.set_title("data")
ax=AX[1]
ax.pcolormesh(X1,X1,pred.reshape((LG, LG)))
ax.set_title("prediction $\\hat y$")
ax=AX[2]
pred01=np.copy(pred)
pred01[pred>0.5]=1
pred01[pred<=0.5]=0
ax.pcolormesh(X1,X1,pred01.reshape((LG, LG)))
ax.set_title("where $\\hat y > 1/2$")
plt.show()








import random

TYPE=3
L=8
N_inc=9000
B=10

# ORIGINAL
x = np.loadtxt(filename("data",L,TYPE), delimiter=' ')
y = np.loadtxt(filename("labels",L,TYPE), delimiter=' ')
y = y.astype("int")

# REDUCTED
index = random.sample(range(len(x)),int(0.5*x.shape[0]))
x_reducted = x[index]
y_reducted = y[index]

x_reducted=np.array(x_reducted)
y_reducted=np.array(y_reducted)


# INCREASED
np.random.seed(1)
x_increased=np.random.random((N_inc,L))*B #number between (0,1) * width of data sample
y_increased=list(np.zeros(N_inc))
for i in range(N_inc):
    y_increased[i]=NF(x_increased[i],B,TYPE)

y_increased=np.array(y_increased)


x_train,y_train,x_test,y_test=prepare_data(x_increased,y_increased)
train_data(x_train,y_train,x_test,y_test)










def reduction(x,y):
    '''
    Returns standardized training and test sets, where the training set gets reducted by half. 
    '''

    perc_train=0.8
    N=len(x)
    N_train = int(perc_train * N)
    x_mean = np.mean(x,axis=0)
    x_std  = np.std(x,axis=0)

    (x_train, y_train) = (x[0:N_train],y[0:N_train])
    (x_test, y_test) = (x[N_train:],y[N_train:])

    index= random.sample(range(len(x_train)),int(0.5*x.shape[0]))
    x_reducted = x_train[index]
    y_reducted = y_train[index]
    #plot_data(x_reducted,y_reducted)
    x_reducted=np.array(x_reducted)
    y_reducted=np.array(y_reducted)

    x_reducted = Standardize(x_reducted,x_mean,x_std)
    x_test = Standardize(x_test,x_mean,x_std)

    #print(x_reducted.shape)
    #print(y_reducted.shape)
    return x_reducted, y_reducted, x_test, y_test


x = np.loadtxt(filename("data",L,TYPE), delimiter=' ')
y = np.loadtxt(filename("labels",L,TYPE), delimiter=' ')
y = y.astype("int")

x_train,y_train,x_test,y_test=reduction(x,y)
plot_data(x_train,y_train)


train_data(x_train,y_train,x_test,y_test)









# AUGMENTED
def augmentation(x,y,n):
    '''
    returns standardized training and test sets.
    given N the length of the training set, the latter gets augmented returning ( N * 2**n ) train data.  
    '''
    perc_train=0.8
    N=len(x)
    N_train = int(perc_train * N)
    x_mean = np.mean(x,axis=0)
    x_std  = np.std(x,axis=0)

    (x_train, y_train) = (x[0:N_train],y[0:N_train])
    (x_test, y_test) = (x[N_train:],y[N_train:])


    N=len(x_train)
    x_augmented=x_train.copy()
    y_augmented=y_train.copy()
    
    for num_iterations in range(n):
        for i in range(0,N):
            lista=[]
            for j in range(L):
                lista.append(np.random.normal(loc=x[i,j],scale=0.1))
            x_augmented=np.append(x_augmented,[lista],axis=0)
            y_aug=y[i]
            y_augmented=np.append(y_augmented,y_aug)

    x_augmented=np.array(x_augmented)
    y_augmented=np.array(y_augmented)

    x_augmented = Standardize(x_augmented,x_mean,x_std)
    x_test = Standardize(x_test,x_mean,x_std)

    return x_augmented,y_augmented,x_test,y_test


x = np.loadtxt(filename("data",L,TYPE), delimiter=' ')
y = np.loadtxt(filename("labels",L,TYPE), delimiter=' ')
y = y.astype("int")

n=2
x_train,y_train,x_test,y_test= augmentation(x,y,n)
plot_data(x_train,y_train)


train_data(x_train,y_train,x_test,y_test)







